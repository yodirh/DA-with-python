{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/saskeli/x/blob/master/pandas2.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n",
    "\n",
    "|                                            -                                            |                                            -                                            |                                            -                                            |\n",
    "|-----------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------|\n",
    "|                    [Exercise 1 (cities)](<#Exercise-1-(cities&#41;>)                    |          [Exercise 2 (powers of series)](<#Exercise-2-(powers-of-series&#41;>)          |     [Exercise 3 (municipal information)](<#Exercise-3-(municipal-information&#41;>)     |\n",
    "| [Exercise 4 (municipalities of finland)](<#Exercise-4-(municipalities-of-finland&#41;>) |    [Exercise 5 (swedish and foreigners)](<#Exercise-5-(swedish-and-foreigners&#41;>)    |    [Exercise 6 (growing municipalities)](<#Exercise-6-(growing-municipalities&#41;>)    |\n",
    "|       [Exercise 7 (subsetting with loc)](<#Exercise-7-(subsetting-with-loc&#41;>)       |   [Exercise 8 (subsetting by positions)](<#Exercise-8-(subsetting-by-positions&#41;>)   |                [Exercise 9 (snow depth)](<#Exercise-9-(snow-depth&#41;>)                |\n",
    "|      [Exercise 10 (average temperature)](<#Exercise-10-(average-temperature&#41;>)      |               [Exercise 11 (below zero)](<#Exercise-11-(below-zero&#41;>)               |                 [Exercise 12 (cyclists)](<#Exercise-12-(cyclists&#41;>)                 |\n",
    "|      [Exercise 13 (missing value types)](<#Exercise-13-(missing-value-types&#41;>)      |   [Exercise 14 (special missing values)](<#Exercise-14-(special-missing-values&#41;>)   |                [Exercise 15 (last week)](<#Exercise-15-(last-week&#41;>)                |\n",
    "|               [Exercise 16 (split date)](<#Exercise-16-(split-date&#41;>)               |            [Exercise 17 (cleaning data)](<#Exercise-17-(cleaning-data&#41;>)            |                                                                                         |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas (continues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of dataframes\n",
    "\n",
    "The DataFrame is essentially a two dimensional object, and it can be created in three different ways:\n",
    "\n",
    "* out of a two dimensional NumPy array\n",
    "* out of given columns\n",
    "* out of given rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div class=\"alert alert-info\">Exercise 1 (cities)</div>\n",
    "\n",
    "Write function `cities` that returns the following DataFrame of top Finnish cities by population:\n",
    "\n",
    "```\n",
    "                 Population Total area\n",
    "Helsinki         643272     715.48\n",
    "Espoo            279044     528.03\n",
    "Tampere          231853     689.59\n",
    "Vantaa           223027     240.35\n",
    "Oulu             201810     3817.52\n",
    "```\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Population  Total area\n",
      "Helsinki      643272      715.48\n",
      "Espoo         279044      528.03\n",
      "Tampere       231853      689.59\n",
      "Vantaa        223027      240.35\n",
      "Oulu          201810     3817.52\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def cities():\n",
    "    w = pd.DataFrame([[643272, 715.48], [279044, 528.03], [231853, 689.59], [223027, 240.35], [201810, 3817.52]], columns=[\"Population\", \"Total area\"],index=[\"Helsinki\", \"Espoo\", \"Tampere\", \"Vantaa\", \"Oulu\"] )\n",
    "    return w\n",
    "    \n",
    "def main():\n",
    "    print(cities())\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div class=\"alert alert-info\">Exercise 2 (powers of series)</div>\n",
    "\n",
    "Make function `powers_of_series` that takes a Series and a positive integer `k` as parameters and returns a DataFrame. The resulting DataFrame should have the same index as the input Series. The first column of the dataFrame should be the input Series, the second column should contain the Series raised to power of two. The third column should contain the Series raised to the power of three, and so on until (and including) power of `k`. The columns should have indices from 1 to k.\n",
    "\n",
    "The values should be numbers, but the index can have any type.\n",
    "Test your function from the `main` function. Example of usage:\n",
    "\n",
    "```\n",
    "s = pd.Series([1,2,3,4], index=list(\"abcd\"))\n",
    "print(powers_of_series(s, 3))\n",
    "```\n",
    "Should print:\n",
    "```\n",
    "   1   2   3\n",
    "a  1   1   1\n",
    "b  2   4   8\n",
    "c  3   9  27\n",
    "d  4  16  64\n",
    "```\n",
    "\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1   2   3\n",
      "a  1   1   1\n",
      "b  2   4   8\n",
      "c  3   9  27\n",
      "d  4  16  64\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def powers_of_series(s, k):\n",
    "    valuesList = []\n",
    "    columnList = []\n",
    "    \n",
    "    for i in range(1,k+1):\n",
    "        valuesList.append(s.values**i)\n",
    "        columnList.append(i)\n",
    "    \n",
    "    d = dict(zip(columnList, valuesList))\n",
    "\n",
    "    w = pd.DataFrame(d, index=s.index)\n",
    "    return w\n",
    "    \n",
    "def main():\n",
    "    s = pd.Series([1,2,3,4], index = list(\"abcd\"))\n",
    "    print(powers_of_series(s, 3))\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div class=\"alert alert-info\">Exercise 3 (municipal information)</div>\n",
    "\n",
    "In the `main` function load a data set of municipal information from the `src` folder (originally from [Statistics Finland](https://pxnet2.stat.fi/PXWeb/pxweb/en/)). Use the function `pd.read_csv`, and note that the separator is a tabulator.\n",
    "\n",
    "Print the shape of the DataFrame (number of rows and columns) and the column names in the following format:\n",
    "```\n",
    "Shape: r,c\n",
    "Columns:\n",
    "col1 \n",
    "col2\n",
    "...\n",
    "```\n",
    "\n",
    "Note, sometimes file ending `tsv` (tab separated values) is used instead of `csv` if the separator is a tab.\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: 490, 7 \n",
      "Columns:\n",
      "Region 2018\n",
      "Population\n",
      "Population change from the previous year, %\n",
      "Share of Swedish-speakers of the population, %\n",
      "Share of foreign citizens of the population, %\n",
      "Proportion of the unemployed among the labour force, %\n",
      "Proportion of pensioners of the population, %\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def main():\n",
    "    data = pd.read_csv(\"municipal.tsv\", sep='\\t')\n",
    "    print(f\"Shape: {data.shape[0]}, {data.shape[1]} \")\n",
    "    print(\"Columns:\" )\n",
    "    for i in data.columns:\n",
    "        print(i)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing columns and rows of a dataframe\n",
    "\n",
    "Even though DataFrames are basically just two dimensional arrays, the way to access their elements is different from NumPy arrays. There are a couple of complications, which we will go through in this section.\n",
    "\n",
    "Firstly, the bracket notation `[]` does not allow the use of an index pair to access a single element of the DataFrame. Instead only one dimension can be specified.\n",
    "\n",
    "Well, does this dimension specify the rows of the DataFrame, like NumPy arrays if only one index is given, or does it specify the columns of the DataFrame?\n",
    "\n",
    "It depends!\n",
    "\n",
    "If an integer is used, then it specifies a column of the DataFrame in the case the **explicit** indices for the column contain that integer. In any other case an error will result. For example, with the above DataFrame, the following indexing will not work, because the explicit column index consist of the column names \"Name\" and \"Wage\" which are not integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div class=\"alert alert-info\">Exercise 4 (municipalities of finland)</div>\n",
    "\n",
    "Load again the municipal information DataFrame. The rows of the DataFrame correspond to various geographical areas of Finland. The first row is about Finland as a whole, then rows from Akaa to Äänekoski are municipalities of Finland in alphabetical order. After that some larger regions are listed.\n",
    "\n",
    "Write function `municipalities_of_finland` that returns a DataFrame containing only rows about municipalities.\n",
    "Give an appropriate argument for `pd.read_csv` so that it interprets the column about region name as the (row) index. This way you can index the DataFrame with the names of the regions.\n",
    "\n",
    "Test your function from the `main` function.\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Population  Population change from the previous year, %  \\\n",
      "Region 2018                                                            \n",
      "Akaa              16769                                         -0.9   \n",
      "Alajärvi           9831                                         -0.7   \n",
      "Alavieska          2610                                         -1.1   \n",
      "Alavus            11713                                         -1.6   \n",
      "Asikkala           8248                                         -0.9   \n",
      "...                 ...                                          ...   \n",
      "Ylivieska         15251                                          0.3   \n",
      "Ylöjärvi          32878                                          0.2   \n",
      "Ypäjä              2372                                         -0.4   \n",
      "Ähtäri             5906                                         -1.3   \n",
      "Äänekoski         19144                                         -1.2   \n",
      "\n",
      "             Share of Swedish-speakers of the population, %  \\\n",
      "Region 2018                                                   \n",
      "Akaa                                                    0.2   \n",
      "Alajärvi                                                0.1   \n",
      "Alavieska                                               0.2   \n",
      "Alavus                                                  0.1   \n",
      "Asikkala                                                0.2   \n",
      "...                                                     ...   \n",
      "Ylivieska                                               0.3   \n",
      "Ylöjärvi                                                0.3   \n",
      "Ypäjä                                                   0.7   \n",
      "Ähtäri                                                  0.1   \n",
      "Äänekoski                                               0.1   \n",
      "\n",
      "             Share of foreign citizens of the population, %  \\\n",
      "Region 2018                                                   \n",
      "Akaa                                                    1.6   \n",
      "Alajärvi                                                1.9   \n",
      "Alavieska                                               0.6   \n",
      "Alavus                                                  1.1   \n",
      "Asikkala                                                1.6   \n",
      "...                                                     ...   \n",
      "Ylivieska                                               1.2   \n",
      "Ylöjärvi                                                1.2   \n",
      "Ypäjä                                                   1.9   \n",
      "Ähtäri                                                  0.9   \n",
      "Äänekoski                                               1.2   \n",
      "\n",
      "             Proportion of the unemployed among the labour force, %  \\\n",
      "Region 2018                                                           \n",
      "Akaa                                                      14.6        \n",
      "Alajärvi                                                  13.9        \n",
      "Alavieska                                                 10.8        \n",
      "Alavus                                                    11.3        \n",
      "Asikkala                                                  12.0        \n",
      "...                                                        ...        \n",
      "Ylivieska                                                 13.3        \n",
      "Ylöjärvi                                                  11.7        \n",
      "Ypäjä                                                     13.2        \n",
      "Ähtäri                                                    13.0        \n",
      "Äänekoski                                                 19.7        \n",
      "\n",
      "             Proportion of pensioners of the population, %  \n",
      "Region 2018                                                 \n",
      "Akaa                                                  26.1  \n",
      "Alajärvi                                              32.0  \n",
      "Alavieska                                             28.4  \n",
      "Alavus                                                31.5  \n",
      "Asikkala                                              35.5  \n",
      "...                                                    ...  \n",
      "Ylivieska                                             23.1  \n",
      "Ylöjärvi                                              20.3  \n",
      "Ypäjä                                                 31.4  \n",
      "Ähtäri                                                35.1  \n",
      "Äänekoski                                             30.5  \n",
      "\n",
      "[311 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def municipalities_of_finland():\n",
    "    w=pd.read_csv(\"municipal.tsv\", sep='\\t', index_col= 0)\n",
    "    w1 = pd.DataFrame(w)    \n",
    "    return w1[\"Akaa\":\"Äänekoski\"]\n",
    "    \n",
    "def main():\n",
    "    print(municipalities_of_finland())\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div class=\"alert alert-info\">Exercise 5 (swedish and foreigners)</div>\n",
    "\n",
    "Write function `swedish_and_foreigners` that\n",
    "\n",
    "* Reads the municipalities data set\n",
    "* Takes the subset about municipalities (like in previous exercise)\n",
    "* Further take a subset of rows that have proportion of Swedish speaking people and proportion of foreigners both above 5 % level\n",
    "* From this data set take only columns about population, the proportions of Swedish speaking people and foreigners, that is three columns.\n",
    "\n",
    "The function should return this final DataFrame.\n",
    "\n",
    "Do you see some kind of correlation between the columns about Swedish speaking and foreign people? Do you see correlation between the columns about the population and the proportion of Swedish speaking people in this subset?\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Population  Share of Swedish-speakers of the population, %  \\\n",
      "Region 2018                                                                 \n",
      "Brändö                452                                            72.6   \n",
      "Eckerö                948                                            89.7   \n",
      "Espoo              279044                                             7.2   \n",
      "Finström             2580                                            89.8   \n",
      "Föglö                 532                                            84.2   \n",
      "Geta                  495                                            86.9   \n",
      "Hammarland           1547                                            89.7   \n",
      "Helsinki           643272                                             5.7   \n",
      "Jomala               4859                                            89.1   \n",
      "Kaskinen             1274                                            29.9   \n",
      "Kirkkonummi         39170                                            16.6   \n",
      "Korsnäs              2154                                            85.8   \n",
      "Kumlinge              314                                            85.4   \n",
      "Kökar                 236                                            87.7   \n",
      "Lapinjärvi           2706                                            31.2   \n",
      "Lemland              2028                                            92.1   \n",
      "Lumparland            395                                            86.6   \n",
      "Mariehamn           11677                                            84.2   \n",
      "Närpiö               9507                                            80.4   \n",
      "Pietarsaari         19379                                            56.2   \n",
      "Saltvik              1873                                            91.9   \n",
      "Sottunga               92                                            93.5   \n",
      "Sund                 1031                                            88.8   \n",
      "Turku              189669                                             5.4   \n",
      "Uusikaarlepyy        7521                                            86.7   \n",
      "Vaasa               67392                                            22.8   \n",
      "Vårdö                 430                                            88.1   \n",
      "Vöyri                6616                                            81.1   \n",
      "\n",
      "               Share of foreign citizens of the population, %  \n",
      "Region 2018                                                    \n",
      "Brändö                                                    8.4  \n",
      "Eckerö                                                   11.5  \n",
      "Espoo                                                    10.5  \n",
      "Finström                                                 10.5  \n",
      "Föglö                                                    17.3  \n",
      "Geta                                                     13.5  \n",
      "Hammarland                                               11.6  \n",
      "Helsinki                                                  9.5  \n",
      "Jomala                                                    8.5  \n",
      "Kaskinen                                                  5.3  \n",
      "Kirkkonummi                                               5.5  \n",
      "Korsnäs                                                   9.1  \n",
      "Kumlinge                                                  8.0  \n",
      "Kökar                                                     8.1  \n",
      "Lapinjärvi                                                5.1  \n",
      "Lemland                                                   8.0  \n",
      "Lumparland                                                9.9  \n",
      "Mariehamn                                                13.0  \n",
      "Närpiö                                                   12.7  \n",
      "Pietarsaari                                               7.1  \n",
      "Saltvik                                                   6.3  \n",
      "Sottunga                                                  5.4  \n",
      "Sund                                                      8.5  \n",
      "Turku                                                     6.5  \n",
      "Uusikaarlepyy                                             6.1  \n",
      "Vaasa                                                     6.0  \n",
      "Vårdö                                                     9.5  \n",
      "Vöyri                                                     5.7  \n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def swedish_and_foreigners():\n",
    "    df = pd.read_csv(\"C:\\municipal.tsv\", sep='\\t', index_col= 0)\n",
    "    df2 = pd.DataFrame(df)\n",
    "    df3 = df2[\"Akaa\":\"Äänekoski\"]\n",
    "    df4=df3[df3[\"Share of Swedish-speakers of the population, %\"]>5] \n",
    "    df5 = df4[df4[\"Share of foreign citizens of the population, %\"]>5]\n",
    "    \n",
    "    return df5[[\"Population\", \"Share of Swedish-speakers of the population, %\", \"Share of foreign citizens of the population, %\"  ]]\n",
    "\n",
    "def main():\n",
    "    print(swedish_and_foreigners())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div class=\"alert alert-info\">Exercise 6 (growing municipalities)</div>\n",
    "\n",
    "Write function `growing_municipalities` that gets subset of municipalities (a DataFrame) as a parameter and returns the proportion of municipalities with increasing population in that subset.\n",
    "\n",
    "Test your function from the `main` function using some subset of the municipalities.\n",
    "Print the proportion as percentages using 1 decimal precision.\n",
    "\n",
    "Example output:\n",
    "\n",
    "```\n",
    "Proportion of growing municipalities: 12.4%\n",
    "```\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Proportion of growing municipalities: 0.2%\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def growing_municipalities(df):\n",
    "    df2 = df[df[\"Population change from the previous year, %\"]>0]\n",
    "    return df2.shape[0]/df.shape[0]\n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv(\"C:\\municipal.tsv\", sep='\\t', index_col= 0)\n",
    "    df = df[\"Akaa\":\"Äänekoski\"]\n",
    "    print(f\" Proportion of growing municipalities: {growing_municipalities(df):.1f}%\")\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative indexing and data selection\n",
    "\n",
    "If the explanation in the previous section sounded confusing or ambiguous, or if you didn't understand a thing, you don't have to worry.\n",
    "\n",
    "There is another way to index Pandas DataFrames, which\n",
    "\n",
    "* allows use of index pairs to access a single element\n",
    "* has the same order of dimensions as NumPy: first index specifies rows, second columns\n",
    "* is not ambiguous about implicit or explicit indices\n",
    "\n",
    "Pandas DataFrames have attributes `loc` and `iloc` that have the above qualities.\n",
    "You can use `loc` and `iloc` attributes and forget everything about the previous section. Or you can use these attributes\n",
    "and sometimes use the methods from the previous section as shortcuts if you understand them well.\n",
    "\n",
    "The difference between `loc` and `iloc` attributes is that the former uses explicit indices and the latter uses the implicit integer indices. Examples of use:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div class=\"alert alert-info\">Exercise 7 (subsetting with loc)</div>\n",
    "\n",
    "Write function `subsetting_with_loc` that in one go takes the subset of municipalities from Akaa to Äänekoski and restricts it to columns: \"Population\", \"Share of Swedish-speakers of the population, %\", and \"Share of foreign citizens of the population, %\".\n",
    "The function should return this content as a DataFrame. Use the attribute `loc`.\n",
    "\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Population  Share of Swedish-speakers of the population, %  \\\n",
      "Region 2018                                                               \n",
      "Akaa              16769                                             0.2   \n",
      "Alajärvi           9831                                             0.1   \n",
      "Alavieska          2610                                             0.2   \n",
      "Alavus            11713                                             0.1   \n",
      "Asikkala           8248                                             0.2   \n",
      "...                 ...                                             ...   \n",
      "Ylivieska         15251                                             0.3   \n",
      "Ylöjärvi          32878                                             0.3   \n",
      "Ypäjä              2372                                             0.7   \n",
      "Ähtäri             5906                                             0.1   \n",
      "Äänekoski         19144                                             0.1   \n",
      "\n",
      "             Share of foreign citizens of the population, %  \n",
      "Region 2018                                                  \n",
      "Akaa                                                    1.6  \n",
      "Alajärvi                                                1.9  \n",
      "Alavieska                                               0.6  \n",
      "Alavus                                                  1.1  \n",
      "Asikkala                                                1.6  \n",
      "...                                                     ...  \n",
      "Ylivieska                                               1.2  \n",
      "Ylöjärvi                                                1.2  \n",
      "Ypäjä                                                   1.9  \n",
      "Ähtäri                                                  0.9  \n",
      "Äänekoski                                               1.2  \n",
      "\n",
      "[311 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def subsetting_with_loc():\n",
    "    df = pd.read_csv(\"municipal.tsv\", sep=\"\\t\", index_col=0)\n",
    "    df = df[\"Akaa\" : \"Äänekoski\"]\n",
    "    df = df.loc[:,[\"Population\", \"Share of Swedish-speakers of the population, %\",\"Share of foreign citizens of the population, %\"]]\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    print(subsetting_with_loc())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div class=\"alert alert-info\">Exercise 8 (subsetting by positions)</div>\n",
    "\n",
    "Write function `subsetting_by_positions` that does the following.\n",
    "\n",
    "Read the data set of the top forty singles from the beginning of the year 1964 from the `src` folder. Return the top 10 entries and only the columns `Title` and `Artist`. Get these elements by their positions, that is, by using a single call to the `iloc` attribute. The function should return these as a DataFrame.\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Title                    Artist\n",
      "0      I WANT TO HOLD YOUR HAND               THE BEATLES\n",
      "1                 GLAD ALL OVER       THE DAVE CLARK FIVE\n",
      "2                 SHE LOVES YOU               THE BEATLES\n",
      "3          YOU WERE MADE FOR ME  FREDDIE AND THE DREAMERS\n",
      "4  TWENTY FOUR HOURS FROM TULSA               GENE PITNEY\n",
      "5    I ONLY WANT TO BE WITH YOU         DUSTY SPRINGFIELD\n",
      "6                     DOMINIQUE           THE SINGING NUN\n",
      "7                   MARIA ELENA      LOS INDIOS TABAJARAS\n",
      "8                   SECRET LOVE               KATHY KIRBY\n",
      "9             DON'T TALK TO HIM             CLIFF RICHARD\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def subsetting_by_positions():\n",
    "    df = pd.read_csv(\"UK-top40-1964-1-2.tsv\", sep=\"\\t\")\n",
    "    return pd.DataFrame(df.iloc[0:10,2:4])\n",
    "\n",
    "def main():\n",
    "    print(subsetting_by_positions())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary statistics\n",
    "\n",
    "The summary statistic methods work in a similar way as their counter parts in NumPy. By default, the aggregation is done over columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div class=\"alert alert-info\">Exercise 9 (snow depth)</div>\n",
    "\n",
    "Write function `snow_depth` that reads in the weather DataFrame from the `src` folder and returns the maximum amount of snow in the year 2017.\n",
    "\n",
    "Print the result in the `main` function in the following form:\n",
    "```\n",
    "Max snow depth: xx.x\n",
    "```\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max snow depth: 15.0\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def snow_depth():\n",
    "    df = pd.read_csv(\"kumpula-weather-2017.csv\")\n",
    "    #df = df.loc[df[\"Snow depth (cm)\"].max()]\n",
    "    #df1 =  df.describe()\n",
    "    #return df1.loc[\"max\",[\"Snow depth (cm)\"]]\n",
    "    return df[\"Snow depth (cm)\"].max()\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(f\"Max snow depth: {snow_depth()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div class=\"alert alert-info\">Exercise 10 (average temperature)</div>\n",
    "\n",
    "Write function `average_temperature` that reads the weather data set and returns the average temperature in July.\n",
    "\n",
    "Print the result in the `main` function in the following form:\n",
    "```\n",
    "Average temperature in July: xx.x\n",
    "```\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average temperature in July: 16.035483870967745\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def average_temperature():\n",
    "    df = pd.read_csv(\"kumpula-weather-2017.csv\")\n",
    "    df1 = df[181:212]\n",
    "    return df1[\"Air temperature (degC)\"].mean()\n",
    "\n",
    "def main():\n",
    "    print(f\"Average temperature in July: {average_temperature()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div class=\"alert alert-info\">Exercise 11 (below zero)</div>\n",
    "\n",
    "Write function `below_zero` that returns the number of days when the temperature was below zero.\n",
    "\n",
    "Print the result in the main function in the following form:\n",
    "\n",
    "```\n",
    "Number of days below zero: xx\n",
    "```\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days below zero: 49\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def below_zero():\n",
    "    df = pd.read_csv(\"kumpula-weather-2017.csv\")\n",
    "    \n",
    "    df1 = df[df[\"Air temperature (degC)\"]<0].count()\n",
    "    return df1[\"d\"]\n",
    "\n",
    "def main():\n",
    "    print(f\"Number of days below zero: {below_zero()}\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data\n",
    "\n",
    "You may have noticed something strange in the output of the `describe` method. First, the minimum value in both precipitation and snow depth fields is -1. The special value -1 means that on that day there was absolutely no snow or rain, whereas the value 0 might indicate that the value was close to zero. Secondly, the snow depth column has count 358, whereas the other columns have count 365, one measurement/value for each day of the year. How is this possible? Every field in a DataFrame should have the same number of rows. Let's use the `unique` method of the Series object to find out, which different values are used in this column:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas excludes the missing values from the summary statistics, like we saw in the previous section. Pandas also provides some functions to handle missing values.\n",
    "\n",
    "The missing values can be located with the `isnull` method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div class=\"alert alert-info\">Exercise 12 (cyclists)</div>\n",
    "\n",
    "Write function `cyclists` that does the following.\n",
    "\n",
    "Load the Helsinki bicycle data set from the `src` folder (https://hri.fi/data/dataset//helsingin-pyorailijamaarat). The dataset contains the number of cyclists passing by measuring points per hour. The data is gathered over about four years, and there are 20 measuring points around Helsinki. The dataset contains some empty rows at the end. Get rid of these. Also, get rid of columns that contain only missing values. Return the cleaned dataset. \n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Päivämäärä  Auroransilta  Eteläesplanadi  \\\n",
      "0        ke 1 tammi 2014 00:00           NaN             7.0   \n",
      "1        ke 1 tammi 2014 01:00           NaN             5.0   \n",
      "2        ke 1 tammi 2014 02:00           NaN             2.0   \n",
      "3        ke 1 tammi 2014 03:00           NaN             5.0   \n",
      "4        ke 1 tammi 2014 04:00           NaN             1.0   \n",
      "...                        ...           ...             ...   \n",
      "37123  ti 27 maalis 2018 19:00          21.0            30.0   \n",
      "37124  ti 27 maalis 2018 20:00          10.0            19.0   \n",
      "37125  ti 27 maalis 2018 21:00           7.0            13.0   \n",
      "37126  ti 27 maalis 2018 22:00           1.0             5.0   \n",
      "37127  ti 27 maalis 2018 23:00           0.0             0.0   \n",
      "\n",
      "       Huopalahti (asema)  Kaisaniemi/Eläintarhanlahti  Kaivokatu  \\\n",
      "0                     NaN                          1.0        NaN   \n",
      "1                     NaN                          3.0        NaN   \n",
      "2                     NaN                          3.0        NaN   \n",
      "3                     NaN                          2.0        NaN   \n",
      "4                     NaN                          4.0        NaN   \n",
      "...                   ...                          ...        ...   \n",
      "37123                18.0                         29.0       51.0   \n",
      "37124                19.0                         12.0       26.0   \n",
      "37125                10.0                          4.0       11.0   \n",
      "37126                 5.0                          6.0        7.0   \n",
      "37127                 0.0                          0.0        4.0   \n",
      "\n",
      "       Kulosaaren silta et.  Kulosaaren silta po.   Kuusisaarentie  \\\n",
      "0                       NaN                    NaN             NaN   \n",
      "1                       NaN                    NaN             NaN   \n",
      "2                       NaN                    NaN             NaN   \n",
      "3                       NaN                    NaN             NaN   \n",
      "4                       NaN                    NaN             NaN   \n",
      "...                     ...                    ...             ...   \n",
      "37123                   0.0                   26.0            31.0   \n",
      "37124                   0.0                   25.0             9.0   \n",
      "37125                   1.0                    4.0            12.0   \n",
      "37126                   0.0                    4.0             1.0   \n",
      "37127                   0.0                    1.0             0.0   \n",
      "\n",
      "       Käpylä, Pohjoisbaana  ...  Merikannontie  \\\n",
      "0                       NaN  ...            NaN   \n",
      "1                       NaN  ...            NaN   \n",
      "2                       NaN  ...            NaN   \n",
      "3                       NaN  ...            NaN   \n",
      "4                       NaN  ...            NaN   \n",
      "...                     ...  ...            ...   \n",
      "37123                  19.0  ...           34.0   \n",
      "37124                  12.0  ...           28.0   \n",
      "37125                   4.0  ...           18.0   \n",
      "37126                   4.0  ...            8.0   \n",
      "37127                   7.0  ...            2.0   \n",
      "\n",
      "       Munkkiniemen silta eteläpuoli  Munkkiniemi silta pohjoispuoli  \\\n",
      "0                                2.0                             5.0   \n",
      "1                                6.0                             5.0   \n",
      "2                                1.0                             1.0   \n",
      "3                                0.0                             2.0   \n",
      "4                                1.0                             1.0   \n",
      "...                              ...                             ...   \n",
      "37123                           31.0                            15.0   \n",
      "37124                           20.0                             8.0   \n",
      "37125                           11.0                             7.0   \n",
      "37126                            5.0                             8.0   \n",
      "37127                            1.0                             2.0   \n",
      "\n",
      "       Heperian puisto/Ooppera  Pitkäsilta itäpuoli  Pitkäsilta länsipuoli  \\\n",
      "0                          3.0                  NaN                   11.0   \n",
      "1                          1.0                  NaN                    8.0   \n",
      "2                          1.0                  NaN                   14.0   \n",
      "3                          0.0                  NaN                    7.0   \n",
      "4                          1.0                  NaN                    9.0   \n",
      "...                        ...                  ...                    ...   \n",
      "37123                     68.0                 39.0                   20.0   \n",
      "37124                     38.0                 24.0                   10.0   \n",
      "37125                     32.0                 25.0                   14.0   \n",
      "37126                      8.0                  8.0                    3.0   \n",
      "37127                      5.0                  6.0                    3.0   \n",
      "\n",
      "       Lauttasaaren silta pohjoispuoli  Ratapihantie  Viikintie  Baana  \n",
      "0                                  NaN           NaN        NaN    8.0  \n",
      "1                                  NaN           NaN        NaN    4.0  \n",
      "2                                  NaN           NaN        NaN   11.0  \n",
      "3                                  NaN           NaN        NaN    3.0  \n",
      "4                                  NaN           NaN        NaN    4.0  \n",
      "...                                ...           ...        ...    ...  \n",
      "37123                             22.0          28.0       12.0   55.0  \n",
      "37124                             21.0          19.0        6.0   43.0  \n",
      "37125                             11.0          17.0        2.0   27.0  \n",
      "37126                              2.0          11.0        0.0   10.0  \n",
      "37127                              2.0           0.0        0.0    4.0  \n",
      "\n",
      "[37128 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def cyclists():\n",
    "    df= pd.read_csv(\"Helsingin_pyorailijamaarat.csv\", sep=\";\")\n",
    "    df1=df.dropna(how=\"all\")\n",
    "    df2= df1.dropna(axis=1, how=\"all\")\n",
    "    \n",
    "    return df2\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(cyclists())\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div class=\"alert alert-info\">Exercise 13 (missing value types)</div>\n",
    "\n",
    "Make function `missing_value_types` that returns the following DataFrame. Use the `State` column as the (row) index. The value types for the two other columns should be `float` and `object`, respectively. Replace the dashes with the appropriate missing value symbols.\n",
    "\n",
    "State | Year of independence | President\n",
    "------|----------------------|----------\n",
    "United Kingdom | - | -\n",
    "Finland | 1917 | Niinistö\n",
    "USA | 1776 | Trump\n",
    "Sweden | 1523 | -\n",
    "Germany | - | Steinmeier\n",
    "Russia | 1992 | Putin\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Year of independence   President\n",
      "State                                           \n",
      "United Kingdom                   NaN        None\n",
      "Finland                       1917.0    Niinistö\n",
      "USA                           1776.0       Trump\n",
      "Sweden                        1523.0        None\n",
      "Germany                          NaN  Steinmeier\n",
      "Russia                        1992.0       Putin\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def missing_value_types():\n",
    "    df= pd.DataFrame([[\"United Kingdom\", np.nan, None], [\"Finland\", 1917, \"Niinistö\"], [\"USA\", 1776, \"Trump\"], [\"Sweden\",\t1523, None\t], [\"Germany\", np.nan, \"Steinmeier\"], \n",
    "    [\"Russia\",\t1992,\t\"Putin\"]], columns=[\"State\", \"Year of independence\", \"President\"])\n",
    "    df1= df.set_index(\"State\")\n",
    "    return df1\n",
    "               \n",
    "def main():\n",
    "    print(missing_value_types())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div class=\"alert alert-info\">Exercise 14 (special missing values)</div>\n",
    "\n",
    "Write function `special_missing_values` that does the following.\n",
    "\n",
    "Read the data set of the top forty singles from the beginning of the year 1964 from the `src` folder. Return the rows whose singles' position dropped compared to last week's position (column LW=Last Week).\n",
    "\n",
    "To do this you first have to convert the special values \"New\" and \"Re\" (Re-entry) to missing values (`None`).\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pos    LW                                 Title  \\\n",
      "2    3.0   2.0                         SHE LOVES YOU   \n",
      "3    4.0   3.0                  YOU WERE MADE FOR ME   \n",
      "5    6.0   5.0            I ONLY WANT TO BE WITH YOU   \n",
      "8    9.0   4.0                           SECRET LOVE   \n",
      "9   10.0   8.0                     DON'T TALK TO HIM   \n",
      "11  12.0  11.0                              GERONIMO   \n",
      "14  15.0  14.0                   I WANNA BE YOUR MAN   \n",
      "15  16.0  12.0               YOU'LL NEVER WALK ALONE   \n",
      "20  21.0  13.0               I'LL KEEP YOU SATISFIED   \n",
      "21  22.0  21.0                  IF I RULED THE WORLD   \n",
      "23  24.0  20.0  ALL I WANT FOR CHRISTMAS IS A BEATLE   \n",
      "29  30.0  22.0                  IT'S ALMOST TOMORROW   \n",
      "30  31.0  24.0                       HUNGRY FOR LOVE   \n",
      "33  34.0  33.0                           DEEP PURPLE   \n",
      "34  35.0  31.0                   BLOWING IN THE WIND   \n",
      "37  38.0  30.0                       SUGAR AND SPICE   \n",
      "38  39.0  37.0                      YESTERDAY'S GONE   \n",
      "\n",
      "                            Artist        Publisher  Peak Pos  WoC  \n",
      "2                      THE BEATLES       PARLOPHONE         1   19  \n",
      "3         FREDDIE AND THE DREAMERS         COLUMBIA         3    9  \n",
      "5                DUSTY SPRINGFIELD          PHILIPS         5    6  \n",
      "8                      KATHY KIRBY            DECCA         4    9  \n",
      "9                    CLIFF RICHARD         COLUMBIA         2    9  \n",
      "11                     THE SHADOWS         COLUMBIA        11    5  \n",
      "14              THE ROLLING STONES            DECCA        13    7  \n",
      "15        GERRY AND THE PACEMAKERS         COLUMBIA         1   13  \n",
      "20  BILLY J KRAMER AND THE DAKOTAS       PARLOPHONE         4    9  \n",
      "21                   HARRY SECOMBE          PHILIPS        18    7  \n",
      "23                      DORA BRYAN          FONTANA        20    5  \n",
      "29                     MARK WYNTER              PYE        12    8  \n",
      "30     JOHNNY KIDD AND THE PIRATES              HMV        20    6  \n",
      "33    NINO TEMPO AND APRIL STEVENS           LONDON        17    8  \n",
      "34            PETER, PAUL AND MARY  WARNER BROTHERS        13   11  \n",
      "37                   THE SEARCHERS              PYE         2   11  \n",
      "38    CHAD STUART AND JEREMY CLYDE            EMBER        37    4  \n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def special_missing_values():\n",
    "    df= pd.read_csv(\"UK-top40-1964-1-2.tsv\",sep=\"\\t\")\n",
    "    df1= df.replace({\"New\":np.nan, \"Re\":np.nan})\n",
    "    df1[\"LW\"]=df1[\"LW\"].astype(float)\n",
    "    df1[\"Pos\"]=df1[\"Pos\"].astype(float)\n",
    "    df2= df1[df1[\"Pos\"]>df1[\"LW\"]]\n",
    "    return df2\n",
    "\n",
    "def main():\n",
    "    print(special_missing_values())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div class=\"alert alert-info\">Exercise 15 (last week)</div>\n",
    "\n",
    "This exercise can give two points at maximum!\n",
    "\n",
    "Write function `last_week` that reads the top40 data set mentioned in the above exercise. The function should then try to reconstruct the top40 list of the previous week based on that week's list. Try to do this as well as possible. You can fill the values that are impossible to reconstruct by missing value symbols. Your solution should work for a top40 list of any week. So don't rely on specific features of this top40 list. The column `WoC` means \"Weeks on Chart\", that is, on how many weeks this song has been on the top 40 list.\n",
    "\n",
    "Hint. First create the last week's top40 list of those songs that are also on this week's list. Then add those entries that were not on this week's list. Finally sort by position.\n",
    "\n",
    "Hint 2. The `where` method of Series and DataFrame can be useful. It can also be nested.\n",
    "\n",
    "Hint 3. Like in NumPy, you can use with Pandas the bitwise operators `&`, `|`, and `~`.\n",
    "Remember that he bitwise operators have higher precedence than the comparison operations, so you may\n",
    "have to use parentheses around comparisons, if you combined result of comparisons with bitwise operators.\n",
    "\n",
    "You get a second point, if you get the columns `LW` and `Peak Pos` correct.\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting columns from one type to another\n",
    "\n",
    "There are several ways of converting a column to another type. For converting single columns (a Series) one can use the `pd.to_numeric` function or the `map` method. For converting several columns in one go one can use the `astype` method. We will give a few examples of use of these methods/functions. For more details, look from the Pandas documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div class=\"alert alert-info\">Exercise 16 (split date)</div>\n",
    "\n",
    "Read again the bicycle data set from `src` folder,\n",
    "and clean it as in the earlier exercise. Then split the `Päivämäärä` column into a DataFrame with five columns with column names `Weekday`, `Day`, `Month`, `Year`, and `Hour`. Note that you also need to to do some conversions. To get Hours, drop the colon and minutes. Convert field `Weekday` according the following rule:\n",
    "```\n",
    "ma -> Mon\n",
    "ti -> Tue\n",
    "ke -> Wed\n",
    "to -> Thu\n",
    "pe -> Fri\n",
    "la -> Sat\n",
    "su -> Sun\n",
    "```\n",
    "Convert the `Month` column according to the following mapping\n",
    "```\n",
    "tammi 1\n",
    "helmi 2\n",
    "maalis 3\n",
    "huhti 4\n",
    "touko 5\n",
    "kesä 6\n",
    "heinä 7\n",
    "elo 8\n",
    "syys 9\n",
    "loka 10\n",
    "marras 11\n",
    "joulu 12\n",
    "```\n",
    "\n",
    "Create function `split_date` that does the above and returns a DataFrame with five columns. You may want to use the `map` method of Series objects.\n",
    "\n",
    "So the first element in the `Päivämäärä` column of the original data set should be converted from\n",
    "`ke 1 tammi 2014 00:00`\n",
    "to\n",
    "`Wed 1 1 2014 0` . Test your solution from the `main` function.\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MoFo\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Weekday  Day  Month  Year  Hour\n",
      "0         Wed    1      1  2014     0\n",
      "1         Wed    1      1  2014     1\n",
      "2         Wed    1      1  2014     2\n",
      "3         Wed    1      1  2014     3\n",
      "4         Wed    1      1  2014     4\n",
      "...       ...  ...    ...   ...   ...\n",
      "37123     Tue   27      3  2018    19\n",
      "37124     Tue   27      3  2018    20\n",
      "37125     Tue   27      3  2018    21\n",
      "37126     Tue   27      3  2018    22\n",
      "37127     Tue   27      3  2018    23\n",
      "\n",
      "[37128 rows x 5 columns]\n",
      "--- 1.6450121402740479 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "def split_date():\n",
    "    df = pd.read_csv(\"Helsingin_pyorailijamaarat.csv\", sep=\"\\;\")\n",
    "    df1=df.dropna(how=\"all\")\n",
    "    df2= df1.dropna(axis=1, how=\"all\")\n",
    "\n",
    "    df3= df2[\"PÃ¤ivÃ¤mÃ¤Ã¤rÃ¤\"].str.split(expand=True)\n",
    "    df3.columns= [\"Weekday\", \"Day\", \"Month\", \"Year\", \"Hour\"]\n",
    "    df3[\"Hour\"] = df3[\"Hour\"].str.split(\":\", expand = True)[0]\n",
    "    df3[\"Weekday\"]= df3[\"Weekday\"].replace({\"ma\":\"Mon\", \"ti\":\"Tue\", \"ke\":\"Wed\",\"to\":\"Thu\",\"pe\":\"Fri\",\"la\":\"Sat\",\"su\":\"Sun\"})\n",
    "    df3[\"Month\"]= df3[\"Month\"].replace({\"tammi\":1, \"helmi\":2, \"maalis\":3,\"huhti\":4, \"touko\":5, \"kesÃ¤\": 6,\"heinÃ¤\": 7,\"elo\" :8,\"syys\" :9,\"loka\": 10,\"marras\" :11,\"joulu\": 12})\n",
    "    df3 = df3.astype({\"Weekday\":object,\"Day\":int,\"Month\":int,\"Year\":int, \"Hour\":int})\n",
    "    return df3\n",
    "\n",
    "def main():\n",
    "    print(split_date())\n",
    "       \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div class=\"alert alert-info\">Exercise 17 (cleaning data)</div>\n",
    "\n",
    "This exercise can give two points at maximum!\n",
    "\n",
    "The entries in the following table of US presidents are not uniformly formatted. Make function `cleaning_data` that reads the table from the tsv file `src/presidents.tsv` and returns the cleaned version of it. Note, you must do the edits programmatically using the string edit methods, not by creating a new DataFrame by hand. The columns should have `dtype`s `object`, `integer`, `float`, `integer`, `object`. The `where` method of DataFrames can be helpful, likewise the [string methods](http://pandas.pydata.org/pandas-docs/stable/api.html#string-handling) of Series objects. You get an additional point, if you manage to get the columns President and Vice-president right!\n",
    "\n",
    "President |\tStart |\tLast |\tSeasons | \tVice-president|\n",
    "----------|-------|------|----------|------------------|\n",
    "donald trump|\t2017 Jan|\t-|\t1|\tMike pence\n",
    "barack obama|\t2009|\t2017|\t2|\tjoe Biden\n",
    "bush, george|\t2001|\t2009|\t2|\tCheney, dick\n",
    "Clinton, Bill|\t1993|\t2001|\ttwo|\tgore, Al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bush, George\n",
      "Clinton, Bill\n",
      "      President  Start    Last  Seasons Vice-president\n",
      "0  Donald Trump   2017     NaN        1     Mike Pence\n",
      "1  Barack Obama   2009  2017.0        2      Joe Biden\n",
      "2   George Bush   2001  2009.0        2    Dick Cheney\n",
      "3  Bill Clinton   1993  2001.0        2        Al Gore\n",
      "--- 0.025999069213867188 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "def cleaning_data():\n",
    "    \n",
    "    df = pd.read_csv(\"presidents.tsv\", sep= \"\\t\")\n",
    "\n",
    "    for i in df[\"President\"]:\n",
    "        if \",\"in i:\n",
    "            print (i)\n",
    "            j=i.split(\", \")\n",
    "            j=j[1]+\" \"+ j[0]\n",
    "            df[\"President\"]=df[\"President\"].replace({i:j})\n",
    "\n",
    "    for i in df[\"Vice-president\"]:\n",
    "        if \",\"in i:\n",
    "            j=i.split(\", \")\n",
    "            j=j[1].capitalize()+\" \"+ j[0].capitalize()\n",
    "            df[\"Vice-president\"]=df[\"Vice-president\"].replace({i:j})\n",
    "        else:\n",
    "            j=i.split(\" \")\n",
    "            j=j[0].capitalize()+\" \"+ j[1].capitalize()\n",
    "            df[\"Vice-president\"]=df[\"Vice-president\"].replace({i:j})     \n",
    "        \n",
    "\n",
    "    df[\"Start\"][0]= df[\"Start\"][0].split()[0]\n",
    "    df[\"Last\"]= df[\"Last\"].replace({\"-\":np.nan})\n",
    "    df[\"Seasons\"]= df[\"Seasons\"].replace({\"two\":2})\n",
    "    df = df.astype({\"President\":object,\"Start\":int,\"Last\":float,\"Seasons\":int,\"Vice-president\":object})\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(cleaning_data())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
